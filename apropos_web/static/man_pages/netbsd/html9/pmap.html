<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="resource-type" content="document">
<link rel="stylesheet" href="/static/man_pages/netbsd/style.css" type="text/css" media="all">
<title>
PMAP(9)</title>
</head>
<body>
<div class="mandoc">
<table summary="Document Header" class="head" width="100%">
<col width="30%">
<col width="30%">
<col width="30%">
<tbody>
<tr>
<td class="head-ltitle">
PMAP(9)</td>
<td class="head-vol" align="center">
Kernel Developer's Manual</td>
<td class="head-rtitle" align="right">
PMAP(9)</td>
</tr>
</tbody>
</table>
<div class="section">
<h1 id="x4e414d45">NAME</h1> <b class="name">pmap</b> &#8212; <span class="desc">machine-dependent portion of the virtual memory system</span></div>
<div class="section">
<h1 id="x53594e4f50534953">SYNOPSIS</h1> <b class="includes">#include &lt;<a class="link-includes">sys/param.h</a>&gt;</b><br>
<b class="includes">#include &lt;<a class="link-includes">uvm/uvm_extern.h</a>&gt;</b><p>
<i class="ftype">void</i><br>
<b class="fname">pmap_init</b>(<i class="farg" style="white-space:nowrap;">void</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_virtual_space</b>(<i class="farg" style="white-space:nowrap;">vaddr_t *vstartp</i>, <i class="farg" style="white-space:nowrap;">vaddr_t *vendp</i>);<p>
<i class="ftype">vaddr_t</i><br>
<b class="fname">pmap_steal_memory</b>(<i class="farg" style="white-space:nowrap;">vsize_t size</i>, <i class="farg" style="white-space:nowrap;">vaddr_t *vstartp</i>, <i class="farg" style="white-space:nowrap;">vaddr_t *vendp</i>);<p>
<i class="ftype">pmap_t</i><br>
<b class="fname">pmap_kernel</b>(<i class="farg" style="white-space:nowrap;">void</i>);<p>
<i class="ftype">pmap_t</i><br>
<b class="fname">pmap_create</b>(<i class="farg" style="white-space:nowrap;">void</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_destroy</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_reference</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_fork</b>(<i class="farg" style="white-space:nowrap;">pmap_t src_map</i>, <i class="farg" style="white-space:nowrap;">pmap_t dst_map</i>);<p>
<i class="ftype">long</i><br>
<b class="fname">pmap_resident_count</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>);<p>
<i class="ftype">long</i><br>
<b class="fname">pmap_wired_count</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>);<p>
<i class="ftype">vaddr_t</i><br>
<b class="fname">pmap_growkernel</b>(<i class="farg" style="white-space:nowrap;">vaddr_t maxkvaddr</i>);<p>
<i class="ftype">int</i><br>
<b class="fname">pmap_enter</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>, <i class="farg" style="white-space:nowrap;">vaddr_t va</i>, <i class="farg" style="white-space:nowrap;">paddr_t pa</i>, <i class="farg" style="white-space:nowrap;">vm_prot_t prot</i>, <i class="farg" style="white-space:nowrap;">u_int flags</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_remove</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>, <i class="farg" style="white-space:nowrap;">vaddr_t sva</i>, <i class="farg" style="white-space:nowrap;">vaddr_t eva</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_remove_all</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_protect</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>, <i class="farg" style="white-space:nowrap;">vaddr_t sva</i>, <i class="farg" style="white-space:nowrap;">vaddr_t eva</i>, <i class="farg" style="white-space:nowrap;">vm_prot_t prot</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_unwire</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>, <i class="farg" style="white-space:nowrap;">vaddr_t va</i>);<p>
<i class="ftype">bool</i><br>
<b class="fname">pmap_extract</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>, <i class="farg" style="white-space:nowrap;">vaddr_t va</i>, <i class="farg" style="white-space:nowrap;">paddr_t *pap</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_kenter_pa</b>(<i class="farg" style="white-space:nowrap;">vaddr_t va</i>, <i class="farg" style="white-space:nowrap;">paddr_t pa</i>, <i class="farg" style="white-space:nowrap;">vm_prot_t prot</i>, <i class="farg" style="white-space:nowrap;">u_int flags</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_kremove</b>(<i class="farg" style="white-space:nowrap;">vaddr_t va</i>, <i class="farg" style="white-space:nowrap;">vsize_t size</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_copy</b>(<i class="farg" style="white-space:nowrap;">pmap_t dst_map</i>, <i class="farg" style="white-space:nowrap;">pmap_t src_map</i>, <i class="farg" style="white-space:nowrap;">vaddr_t dst_addr</i>, <i class="farg" style="white-space:nowrap;">vsize_t len</i>, <i class="farg" style="white-space:nowrap;">vaddr_t src_addr</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_update</b>(<i class="farg" style="white-space:nowrap;">pmap_t pmap</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_activate</b>(<i class="farg" style="white-space:nowrap;">struct lwp *l</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_deactivate</b>(<i class="farg" style="white-space:nowrap;">struct lwp *l</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_zero_page</b>(<i class="farg" style="white-space:nowrap;">paddr_t pa</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_copy_page</b>(<i class="farg" style="white-space:nowrap;">paddr_t src</i>, <i class="farg" style="white-space:nowrap;">paddr_t dst</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">pmap_page_protect</b>(<i class="farg" style="white-space:nowrap;">struct vm_page *pg</i>, <i class="farg" style="white-space:nowrap;">vm_prot_t prot</i>);<p>
<i class="ftype">bool</i><br>
<b class="fname">pmap_clear_modify</b>(<i class="farg" style="white-space:nowrap;">struct vm_page *pg</i>);<p>
<i class="ftype">bool</i><br>
<b class="fname">pmap_clear_reference</b>(<i class="farg" style="white-space:nowrap;">struct vm_page *pg</i>);<p>
<i class="ftype">bool</i><br>
<b class="fname">pmap_is_modified</b>(<i class="farg" style="white-space:nowrap;">struct vm_page *pg</i>);<p>
<i class="ftype">bool</i><br>
<b class="fname">pmap_is_referenced</b>(<i class="farg" style="white-space:nowrap;">struct vm_page *pg</i>);<p>
<i class="ftype">paddr_t</i><br>
<b class="fname">pmap_phys_address</b>(<i class="farg" style="white-space:nowrap;">paddr_t cookie</i>);<p>
<i class="ftype">vaddr_t</i><br>
<b class="fname">PMAP_MAP_POOLPAGE</b>(<i class="farg" style="white-space:nowrap;">paddr_t pa</i>);<p>
<i class="ftype">paddr_t</i><br>
<b class="fname">PMAP_UNMAP_POOLPAGE</b>(<i class="farg" style="white-space:nowrap;">vaddr_t va</i>);<p>
<i class="ftype">void</i><br>
<b class="fname">PMAP_PREFER</b>(<i class="farg" style="white-space:nowrap;">vaddr_t hint</i>, <i class="farg" style="white-space:nowrap;">vaddr_t *vap</i>, <i class="farg" style="white-space:nowrap;">vsize_t sz</i>, <i class="farg" style="white-space:nowrap;">int td</i>);</div>
<div class="section">
<h1 id="x4445534352495054494f4e">DESCRIPTION</h1> The <b class="name">pmap</b> module is the machine-dependent portion of the <span class="unix">NetBSD</span> virtual memory system <a class="link-man" href="../9/uvm">uvm(9)</a>. The purpose of the <b class="name">pmap</b> module is to manage physical address maps, to program the memory management hardware on the system, and perform any cache operations necessary to ensure correct operation of the virtual memory system. The <b class="name">pmap</b> module is also responsible for maintaining certain information required by <a class="link-man" href="../9/uvm">uvm(9)</a>.<p>
In order to cope with hardware architectures that make the invalidation of virtual address mappings expensive (e.g., TLB invalidations, TLB shootdown operations for multiple processors), the <b class="name">pmap</b> module is allowed to delay mapping invalidation or protection operations until such time as they are actually necessary. The functions that are allowed to delay such actions are <b class="fname">pmap_enter</b>(), <b class="fname">pmap_remove</b>(), <b class="fname">pmap_protect</b>(), <b class="fname">pmap_kenter_pa</b>(), and <b class="fname">pmap_kremove</b>(). Callers of these functions must use the <b class="fname">pmap_update</b>() function to notify the <b class="name">pmap</b> module that the mappings need to be made correct. Since the <b class="name">pmap</b> module is provided with information as to which processors are using a given physical map, the <b class="name">pmap</b> module may use whatever optimizations it has available to reduce the expense of virtual-to-physical mapping synchronization.<div class="subsection">
<h2 id="x4845414445522046494c455320414e4420444154412053545255435455524553">HEADER FILES AND DATA STRUCTURES</h2> Machine-dependent code must provide the header file <b class="includes">&lt;<a class="link-includes">machine/pmap.h</a>&gt;</b>. This file contains the definition of the <span class="define">pmap</span> structure:<p>
<pre style="margin-left: 5.00ex;" class="lit display">
struct pmap { 
        /* Contents defined by pmap implementation. */ 
}; 
typedef struct pmap *pmap_t;</pre>
<p>
This header file may also define other data structures that the <b class="name">pmap</b> implementation uses.<p>
Note that all prototypes for <b class="name">pmap</b> interface functions are provided by the header file <b class="includes">&lt;<a class="link-includes">uvm/uvm_pmap.h</a>&gt;</b>. It is possible to override this behavior by defining the C pre-processor macro <span class="define">PMAP_EXCLUDE_DECLS</span>. This may be used to add a layer of indirection to <b class="name">pmap</b> API calls, for handling different MMU types in a single <b class="name">pmap</b> module, for example. If the <span class="define">PMAP_EXCLUDE_DECLS</span> macro is defined, <b class="includes">&lt;<a class="link-includes">machine/pmap.h</a>&gt;</b> <span class="emph">must</span> provide function prototypes in a block like so:<p>
<pre style="margin-left: 5.00ex;" class="lit display">
#ifdef _KERNEL /* not exposed to user namespace */ 
__BEGIN_DECLS  /* make safe for C++ */ 
/* Prototypes go here. */ 
__END_DECLS 
#endif /* _KERNEL */</pre>
<p>
The header file <b class="includes">&lt;<a class="link-includes">uvm/uvm_pmap.h</a>&gt;</b> defines a structure for tracking <b class="name">pmap</b> statistics (see below). This structure is defined as:<p>
<pre style="margin-left: 5.00ex;" class="lit display">
struct pmap_statistics { 
        long        resident_count; /* number of mapped pages */ 
        long        wired_count;    /* number of wired pages */ 
};</pre>
</div>
<div class="subsection">
<h2 id="x5749524544204d415050494e4753">WIRED MAPPINGS</h2> The <b class="name">pmap</b> module is based on the premise that all information contained in the physical maps it manages is redundant. That is, physical map information may be &#8220;forgotten&#8221; by the <b class="name">pmap</b> module in the event that it is necessary to do so; it can be rebuilt by <a class="link-man" href="../9/uvm">uvm(9)</a> by taking a page fault. There is one exception to this rule: so-called &#8220;wired&#8221; mappings may not be forgotten. Wired mappings are those for which either no high-level information exists with which to rebuild the mapping, or mappings which are needed by critical sections of code where taking a page fault is unacceptable. Information about which mappings are wired is provided to the <b class="name">pmap</b> module when a mapping is established.</div>
<div class="subsection">
<h2 id="x4d4f4449464945442f5245464552454e43454420494e464f524d4154494f4e">MODIFIED/REFERENCED INFORMATION</h2> The <b class="name">pmap</b> module is required to keep track of whether or not a page managed by the virtual memory system has been referenced or modified. This information is used by <a class="link-man" href="../9/uvm">uvm(9)</a> to determine what happens to the page when scanned by the pagedaemon.<p>
Many CPUs provide hardware support for tracking modified/referenced information. However, many CPUs, particularly modern RISC CPUs, do not. On CPUs which lack hardware support for modified/referenced tracking, the <b class="name">pmap</b> module must emulate it in software. There are several strategies for doing this, and the best strategy depends on the CPU.<p>
The &#8220;referenced&#8221; attribute is used by the pagedaemon to determine if a page is &#8220;active&#8221;. Active pages are not candidates for re-use in the page replacement algorithm. Accurate referenced information is not required for correct operation; if supplying referenced information for a page is not feasible, then the <b class="name">pmap</b> implementation should always consider the &#8220;referenced&#8221; attribute to be <span class="define">false</span>.<p>
The &#8220;modified&#8221; attribute is used by the pagedaemon to determine if a page needs to be cleaned (written to backing store; swap space, a regular file, etc.). Accurate modified information <span class="emph">must</span> be provided by the <b class="name">pmap</b> module for correct operation of the virtual memory system.<p>
Note that modified/referenced information is only tracked for pages managed by the virtual memory system (i.e., pages for which a vm_page structure exists). In addition, only &#8220;managed&#8221; mappings of those pages have modified/referenced tracking. Mappings entered with the <b class="fname">pmap_enter</b>() function are &#8220;managed&#8221; mappings. It is possible for &#8220;unmanaged&#8221; mappings of a page to be created, using the <b class="fname">pmap_kenter_pa</b>() function. The use of &#8220;unmanaged&#8221; mappings should be limited to code which may execute in interrupt context (for example, the kernel memory allocator), or to enter mappings for physical addresses which are not managed by the virtual memory system. &#8220;Unmanaged&#8221; mappings may only be entered into the kernel's virtual address space. This constraint is placed on the callers of the <b class="fname">pmap_kenter_pa</b>() and <b class="fname">pmap_kremove</b>() functions so that the <b class="name">pmap</b> implementation need not block interrupts when manipulating data structures or holding locks.<p>
Also note that the modified/referenced information must be tracked on a per-page basis; they are not attributes of a mapping, but attributes of a page. Therefore, even after all mappings for a given page have been removed, the modified/referenced information for that page <span class="emph">must</span> be preserved. The only time the modified/referenced attributes may be cleared is when the virtual memory system explicitly calls the <b class="fname">pmap_clear_modify</b>() and <b class="fname">pmap_clear_reference</b>() functions. These functions must also change any internal state necessary to detect the page being modified or referenced again after the modified or referenced state is cleared. (Prior to <span class="unix">NetBSD&#160;1.6</span>, <b class="name">pmap</b> implementations could get away without this because UVM (and Mach VM before that) always called <b class="fname">pmap_page_protect</b>() before clearing the modified or referenced state, but UVM has been changed to not do this anymore, so all <b class="name">pmap</b> implementations must now handle this.)</div>
<div class="subsection">
<h2 id="x53544154495354494353">STATISTICS</h2> The <b class="name">pmap</b> is required to keep statistics as to the number of &#8220;resident&#8221; pages and the number of &#8220;wired&#8221; pages.<p>
A &#8220;resident&#8221; page is one for which a mapping exists. This statistic is used to compute the resident size of a process and enforce resource limits. Only pages (whether managed by the virtual memory system or not) which are mapped into a physical map should be counted in the resident count.<p>
A &#8220;wired&#8221; page is one for which a wired mapping exists. This statistic is used to enforce resource limits.<p>
Note that it is recommended (though not required) that the <b class="name">pmap</b> implementation use the <span class="define">pmap_statistics</span> structure in the tracking of <b class="name">pmap</b> statistics by placing it inside the <span class="define">pmap</span> structure and adjusting the counts when mappings are established, changed, or removed. This avoids potentially expensive data structure traversals when the statistics are queried.</div>
<div class="subsection">
<h2 id="x52455155495245442046554e4354494f4e53">REQUIRED FUNCTIONS</h2> This section describes functions that a <b class="name">pmap</b> module must provide to the virtual memory system.<dl style="margin-top: 0.00em;margin-bottom: 0.00em;margin-left: 5.00ex;" class="list list-tag">
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_init</b>(<i class="farg">void</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
This function initializes the <b class="name">pmap</b> module. It is called by <b class="fname">uvm_init</b>() to initialize any data structures that the module needs to manage physical maps.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
pmap_t <b class="fname">pmap_kernel</b>(<i class="farg">void</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
A machine independent macro which expands to <b class="var">kernel_pmap_ptr</b>. This variable must be exported by the platform's pmap module and it must point to the kernel pmap.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_virtual_space</b>(<i class="farg">vaddr_t *vstartp</i>, <i class="farg">vaddr_t *vendp</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
The <b class="fname">pmap_virtual_space</b>() function is called to determine the initial kernel virtual address space beginning and end. These values are used to create the kernel's virtual memory map. The function must set <i class="farg">*vstartp</i> to the first kernel virtual address that will be managed by <a class="link-man" href="../9/uvm">uvm(9)</a>, and must set <i class="farg">*vendp</i> to the last kernel virtual address that will be managed by <a class="link-man" href="../9/uvm">uvm(9)</a>.<p>
If the <b class="fname">pmap_growkernel</b>() feature is used by a <b class="name">pmap</b> implementation, then <i class="farg">*vendp</i> should be set to the maximum kernel virtual address allowed by the implementation. If <b class="fname">pmap_growkernel</b>() is not used, then <i class="farg">*vendp</i> <span class="emph">must</span> be set to the maximum kernel virtual address that can be mapped with the resources currently allocated to map the kernel virtual address space.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
pmap_t <b class="fname">pmap_create</b>(<i class="farg">void</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Create a physical map and return it to the caller. The reference count on the new map is 1.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_destroy</b>(<i class="farg">pmap_t pmap</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Drop the reference count on the specified physical map. If the reference count drops to 0, all resources associated with the physical map are released and the physical map destroyed. In the case of a drop-to-0, no mappings will exist in the map. The <b class="name">pmap</b> implementation may assert this.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_reference</b>(<i class="farg">pmap_t pmap</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Increment the reference count on the specified physical map.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
long <b class="fname">pmap_resident_count</b>(<i class="farg">pmap_t pmap</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Query the &#8220;resident pages&#8221; statistic for <i class="farg">pmap</i>.<p>
Note that this function may be provided as a C pre-processor macro.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
long <b class="fname">pmap_wired_count</b>(<i class="farg">pmap_t pmap</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Query the &#8220;wired pages&#8221; statistic for <i class="farg">pmap</i>.<p>
Note that this function may be provided as a C pre-processor macro.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
int <b class="fname">pmap_enter</b>(<i class="farg">pmap_t pmap</i>, <i class="farg">vaddr_t va</i>, <i class="farg">paddr_t pa</i>, <i class="farg">vm_prot_t prot</i>, <i class="farg">u_int flags</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Create a mapping in physical map <i class="farg">pmap</i> for the physical address <i class="farg">pa</i> at the virtual address <i class="farg">va</i> with protection specified by bits in <i class="farg">prot</i>:<dl style="margin-top: 0.00em;margin-bottom: 0.00em;margin-left: 5.00ex;" class="list list-tag">
<dt class="list-tag" style="margin-top: 1.00em;">
VM_PROT_READ</dt>
<dd class="list-tag" style="margin-left: 17.00ex;">
The mapping must allow reading.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
VM_PROT_WRITE</dt>
<dd class="list-tag" style="margin-left: 17.00ex;">
The mapping must allow writing.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
VM_PROT_EXECUTE</dt>
<dd class="list-tag" style="margin-left: 17.00ex;">
The page mapped contains instructions that will be executed by the processor.</dd>
</dl>
<p>
The <i class="farg">flags</i> argument contains protection bits (the same bits as used in the <i class="farg">prot</i> argument) indicating the type of access that caused the mapping to be created. This information may be used to seed modified/referenced information for the page being mapped, possibly avoiding redundant faults on platforms that track modified/referenced information in software. Other information provided by <i class="farg">flags</i>:<dl style="margin-top: 0.00em;margin-bottom: 0.00em;margin-left: 5.00ex;" class="list list-tag">
<dt class="list-tag" style="margin-top: 1.00em;">
PMAP_WIRED</dt>
<dd class="list-tag" style="margin-left: 14.00ex;">
The mapping being created is a wired mapping.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
PMAP_CANFAIL</dt>
<dd class="list-tag" style="margin-left: 14.00ex;">
The call to <b class="fname">pmap_enter</b>() is allowed to fail. If this flag is <span class="emph">not</span> set, and the <b class="fname">pmap_enter</b>() call is unable to create the mapping, perhaps due to insufficient resources, the <b class="name">pmap</b> module must panic.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
PMAP_NOCACHE</dt>
<dd class="list-tag" style="margin-left: 14.00ex;">
The mapping being created is <span class="emph">not</span> cached. Write accesses have a write-through policy. No speculative memory accesses.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
PMAP_WRITE_COMBINE</dt>
<dd class="list-tag" style="margin-left: 14.00ex;">
The mapping being created is <span class="emph">not</span> cached. Writes are combined and done in one burst. Speculative read accesses may be allowed.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
PMAP_WRITE_BACK</dt>
<dd class="list-tag" style="margin-left: 14.00ex;">
All accesses to the created mapping are cached. On reads, cachelines become shared or exclusive if allocated on cache miss. On writes, cachelines become modified on a cache miss.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
PMAP_NOCACHE_OVR</dt>
<dd class="list-tag" style="margin-left: 14.00ex;">
Same as PMAP_NOCACHE but mapping is overrideable (e.g. on x86 by MTRRs).</dd>
</dl>
<p>
The access type provided in the <i class="farg">flags</i> argument will never exceed the protection specified by <i class="farg">prot</i>. The <b class="name">pmap</b> implementation may assert this. Note that on systems that do not provide hardware support for tracking modified/referenced information, modified/referenced information for the page <span class="emph">must</span> be seeded with the access type provided in <i class="farg">flags</i> if the <span class="define">PMAP_WIRED</span> flag is set. This is to prevent a fault for the purpose of tracking modified/referenced information from occurring while the system is in a critical section where a fault would be unacceptable.<p>
Note that <b class="fname">pmap_enter</b>() is sometimes called to enter a mapping at a virtual address for which a mapping already exists. In this situation, the implementation must take whatever action is necessary to invalidate the previous mapping before entering the new one.<p>
Also note that <b class="fname">pmap_enter</b>() is sometimes called to change the protection for a pre-existing mapping, or to change the &#8220;wired&#8221; attribute for a pre-existing mapping.<p>
The <b class="fname">pmap_enter</b>() function returns 0 on success or an error code indicating the mode of failure.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_remove</b>(<i class="farg">pmap_t pmap</i>, <i class="farg">vaddr_t sva</i>, <i class="farg">vaddr_t eva</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Remove mappings from the virtual address range <i class="farg">sva</i> to <i class="farg">eva</i> from the specified physical map.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_remove_all</b>(<i class="farg">pmap_t pmap</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
This function is a hint to the <b class="name">pmap</b> implementation that all entries in <i class="farg">pmap</i> will be removed before any more entries are entered. Following this call, there will be <b class="fname">pmap_remove</b>() calls resulting in every mapping being removed, followed by either <b class="fname">pmap_destroy</b>() or <b class="fname">pmap_update</b>(). No other <b class="name">pmap</b> interfaces which take <i class="farg">pmap</i> as an argument will be called during this process. Other interfaces which might need to access <i class="farg">pmap</i> (such as <b class="fname">pmap_page_protect</b>()) are permitted during this process.<p>
The <b class="name">pmap</b> implementation is free to either remove all the <b class="name">pmap</b>'s mappings immediately in <b class="fname">pmap_remove_all</b>(), or to use the knowledge of the upcoming <b class="fname">pmap_remove</b>() calls to optimize the removals (or to just ignore this call).</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_protect</b>(<i class="farg">pmap_t pmap</i>, <i class="farg">vaddr_t sva</i>, <i class="farg">vaddr_t eva</i>, <i class="farg">vm_prot_t prot</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Set the protection of the mappings in the virtual address range <i class="farg">sva</i> to <i class="farg">eva</i> in the specified physical map.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_unwire</b>(<i class="farg">pmap_t pmap</i>, <i class="farg">vaddr_t va</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Clear the &#8220;wired&#8221; attribute on the mapping for virtual address <i class="farg">va</i>.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
bool <b class="fname">pmap_extract</b>(<i class="farg">pmap_t pmap</i>, <i class="farg">vaddr_t va</i>, <i class="farg">paddr_t *pap</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
This function extracts a mapping from the specified physical map. It serves two purposes: to determine if a mapping exists for the specified virtual address, and to determine what physical address is mapped at the specified virtual address. The <b class="fname">pmap_extract</b>() should return the physical address for any kernel-accessible address, including KSEG-style direct-mapped kernel addresses.<p>
The <b class="fname">pmap_extract</b>() function returns <span class="define">false</span> if a mapping for <i class="farg">va</i> does not exist. Otherwise, it returns <span class="define">true</span> and places the physical address mapped at <i class="farg">va</i> into <i class="farg">*pap</i> if the <i class="farg">pap</i> argument is non-NULL.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_kenter_pa</b>(<i class="farg">vaddr_t va</i>, <i class="farg">paddr_t pa</i>, <i class="farg">vm_prot_t prot</i>, <i class="farg">u_int flags</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Enter an &#8220;unmanaged&#8221; mapping for physical address <i class="farg">pa</i> at virtual address <i class="farg">va</i> with protection specified by bits in <i class="farg">prot</i>:<dl style="margin-top: 0.00em;margin-bottom: 0.00em;margin-left: 5.00ex;" class="list list-tag">
<dt class="list-tag" style="margin-top: 1.00em;">
VM_PROT_READ</dt>
<dd class="list-tag" style="margin-left: 17.00ex;">
The mapping must allow reading.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
VM_PROT_WRITE</dt>
<dd class="list-tag" style="margin-left: 17.00ex;">
The mapping must allow writing.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
VM_PROT_EXECUTE</dt>
<dd class="list-tag" style="margin-left: 17.00ex;">
The page mapped contains instructions that will be executed by the processor.</dd>
</dl>
<p>
Information provided by <i class="farg">flags</i>:<dl style="margin-top: 0.00em;margin-bottom: 0.00em;margin-left: 5.00ex;" class="list list-tag">
<dt class="list-tag" style="margin-top: 1.00em;">
PMAP_NOCACHE</dt>
<dd class="list-tag" style="margin-left: 14.00ex;">
The mapping being created is <span class="emph">not</span> cached. Write accesses have a write-through policy. No speculative memory accesses.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
PMAP_WRITE_COMBINE</dt>
<dd class="list-tag" style="margin-left: 14.00ex;">
The mapping being created is <span class="emph">not</span> cached. Writes are combined and done in one burst. Speculative read accesses may be allowed.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
PMAP_WRITE_BACK</dt>
<dd class="list-tag" style="margin-left: 14.00ex;">
All accesses to the created mapping are cached. On reads, cachelines become shared or exclusive if allocated on cache miss. On writes, cachelines become modified on a cache miss.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
PMAP_NOCACHE_OVR</dt>
<dd class="list-tag" style="margin-left: 14.00ex;">
Same as PMAP_NOCACHE but mapping is overrideable (e.g. on x86 by MTRRs).</dd>
</dl>
<p>
Mappings of this type are always &#8220;wired&#8221;, and are unaffected by routines that alter the protection of pages (such as <b class="fname">pmap_page_protect</b>()). Such mappings are also not included in the gathering of modified/referenced information about a page. Mappings entered with <b class="fname">pmap_kenter_pa</b>() by machine-independent code <span class="emph">must not</span> have execute permission, as the data structures required to track execute permission of a page may not be available to <b class="fname">pmap_kenter_pa</b>(). Machine-independent code is not allowed to enter a mapping with <b class="fname">pmap_kenter_pa</b>() at a virtual address for which a valid mapping already exists. Mappings created with <b class="fname">pmap_kenter_pa</b>() may be removed only with a call to <b class="fname">pmap_kremove</b>().<p>
Note that <b class="fname">pmap_kenter_pa</b>() must be safe for use in interrupt context. <b class="fname">splvm</b>() blocks interrupts that might cause <b class="fname">pmap_kenter_pa</b>() to be called.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_kremove</b>(<i class="farg">vaddr_t va</i>, <i class="farg">vsize_t size</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Remove all mappings starting at virtual address <i class="farg">va</i> for <i class="farg">size</i> bytes from the kernel physical map. All mappings that are removed must be the &#8220;unmanaged&#8221; type created with <b class="fname">pmap_kenter_pa</b>(). The implementation may assert this.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_copy</b>(<i class="farg">pmap_t dst_map</i>, <i class="farg">pmap_t src_map</i>, <i class="farg">vaddr_t dst_addr</i>, <i class="farg">vsize_t len</i>, <i class="farg">vaddr_t src_addr</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
This function copies the mappings starting at <i class="farg">src_addr</i> in <i class="farg">src_map</i> for <i class="farg">len</i> bytes into <i class="farg">dst_map</i> starting at <i class="farg">dst_addr</i>.<p>
Note that while this function is required to be provided by a <b class="name">pmap</b> implementation, it is not actually required to do anything. <b class="fname">pmap_copy</b>() is merely advisory (it is used in the <a class="link-man" href="../2/fork">fork(2)</a> path to &#8220;pre-fault&#8221; the child's address space).</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_update</b>(<i class="farg">pmap_t pmap</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
This function is used to inform the <b class="name">pmap</b> module that all physical mappings, for the specified pmap, must now be correct. That is, all delayed virtual-to-physical mappings updates (such as TLB invalidation or address space identifier updates) must be completed. This routine must be used after calls to <b class="fname">pmap_enter</b>(), <b class="fname">pmap_remove</b>(), <b class="fname">pmap_protect</b>(), <b class="fname">pmap_kenter_pa</b>(), and <b class="fname">pmap_kremove</b>() in order to ensure correct operation of the virtual memory system.<p>
If a <b class="name">pmap</b> implementation does not delay virtual-to-physical mapping updates, <b class="fname">pmap_update</b>() has no operation. In this case, the call may be deleted using a C pre-processor macro in <b class="includes">&lt;<a class="link-includes">machine/pmap.h</a>&gt;</b>.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_activate</b>(<i class="farg">struct lwp *l</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Activate the physical map used by the process behind lwp <i class="farg">l</i>. This is called by the virtual memory system when the virtual memory context for a process is changed, and is also often used by machine-dependent context switch code to program the memory management hardware with the process's page table base, etc. Note that <b class="fname">pmap_activate</b>() may not always be called when <i class="farg">l</i> is the current lwp. <b class="fname">pmap_activate</b>() must be able to handle this scenario.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_deactivate</b>(<i class="farg">struct lwp *l</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Deactivate the physical map used by the process behind lwp <i class="farg">l</i>. It is generally used in conjunction with <b class="fname">pmap_activate</b>(). Like <b class="fname">pmap_activate</b>(), <b class="fname">pmap_deactivate</b>() may not always be called when <i class="farg">l</i> is the current lwp.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_zero_page</b>(<i class="farg">paddr_t pa</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Zero the PAGE_SIZE sized region starting at physical address <i class="farg">pa</i>. The <b class="name">pmap</b> implementation must take whatever steps are necessary to map the page to a kernel-accessible address and zero the page. It is suggested that implementations use an optimized zeroing algorithm, as the performance of this function directly impacts page fault performance. The implementation may assume that the region is PAGE_SIZE aligned and exactly PAGE_SIZE bytes in length.<p>
Note that the cache configuration of the platform should also be considered in the implementation of <b class="fname">pmap_zero_page</b>(). For example, on systems with a physically-addressed cache, the cache load caused by zeroing the page will not be wasted, as the zeroing is usually done on-demand. However, on systems with a virtually-addressed cached, the cache load caused by zeroing the page <span class="emph">will</span> be wasted, as the page will be mapped at a virtual address which is different from that used to zero the page. In the virtually-addressed cache case, care should also be taken to avoid cache alias problems.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_copy_page</b>(<i class="farg">paddr_t src</i>, <i class="farg">paddr_t dst</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Copy the PAGE_SIZE sized region starting at physical address <i class="farg">src</i> to the same sized region starting at physical address <i class="farg">dst</i>. The <b class="name">pmap</b> implementation must take whatever steps are necessary to map the source and destination pages to a kernel-accessible address and perform the copy. It is suggested that implementations use an optimized copy algorithm, as the performance of this function directly impacts page fault performance. The implementation may assume that both regions are PAGE_SIZE aligned and exactly PAGE_SIZE bytes in length.<p>
The same cache considerations that apply to <b class="fname">pmap_zero_page</b>() apply to <b class="fname">pmap_copy_page</b>().</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_page_protect</b>(<i class="farg">struct vm_page *pg</i>, <i class="farg">vm_prot_t prot</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Lower the permissions for all mappings of the page <i class="farg">pg</i> to <i class="farg">prot</i>. This function is used by the virtual memory system to implement copy-on-write (called with VM_PROT_READ set in <i class="farg">prot</i>) and to revoke all mappings when cleaning a page (called with no bits set in <i class="farg">prot</i>). Access permissions must never be added to a page as a result of this call.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
bool <b class="fname">pmap_clear_modify</b>(<i class="farg">struct vm_page *pg</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Clear the &#8220;modified&#8221; attribute on the page <i class="farg">pg</i>.<p>
The <b class="fname">pmap_clear_modify</b>() function returns <span class="define">true</span> or <span class="define">false</span> indicating whether or not the &#8220;modified&#8221; attribute was set on the page before it was cleared.<p>
Note that this function may be provided as a C pre-processor macro.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
bool <b class="fname">pmap_clear_reference</b>(<i class="farg">struct vm_page *pg</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Clear the &#8220;referenced&#8221; attribute on the page <i class="farg">pg</i>.<p>
The <b class="fname">pmap_clear_reference</b>() function returns <span class="define">true</span> or <span class="define">false</span> indicating whether or not the &#8220;referenced&#8221; attribute was set on the page before it was cleared.<p>
Note that this function may be provided as a C pre-processor macro.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
bool <b class="fname">pmap_is_modified</b>(<i class="farg">struct vm_page *pg</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Test whether or not the &#8220;modified&#8221; attribute is set on page <i class="farg">pg</i>.<p>
Note that this function may be provided as a C pre-processor macro.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
bool <b class="fname">pmap_is_referenced</b>(<i class="farg">struct vm_page *pg</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Test whether or not the &#8220;referenced&#8221; attribute is set on page <i class="farg">pg</i>.<p>
Note that this function may be provided as a C pre-processor macro.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
paddr_t <b class="fname">pmap_phys_address</b>(<i class="farg">paddr_t cookie</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Convert a cookie returned by a device <b class="fname">mmap</b>() function into a physical address. This function is provided to accommodate systems which have physical address spaces larger than can be directly addressed by the platform's <i class="farg">paddr_t</i> type. The existence of this function is highly dubious, and it is expected that this function will be removed from the <b class="name">pmap</b> API in a future release of <span class="unix">NetBSD</span>.<p>
Note that this function may be provided as a C pre-processor macro.</dd>
</dl>
</div>
<div class="subsection">
<h2 id="x4f5054494f4e414c2046554e4354494f4e53">OPTIONAL FUNCTIONS</h2> This section describes several optional functions in the <b class="name">pmap</b> API.<dl style="margin-top: 0.00em;margin-bottom: 0.00em;margin-left: 5.00ex;" class="list list-tag">
<dt class="list-tag" style="margin-top: 1.00em;">
vaddr_t <b class="fname">pmap_steal_memory</b>(<i class="farg">vsize_t size</i>, <i class="farg">vaddr_t *vstartp</i>, <i class="farg">vaddr_t *vendp</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
This function is a bootstrap memory allocator, which may be provided as an alternative to the bootstrap memory allocator used within <a class="link-man" href="../9/uvm">uvm(9)</a> itself. It is particularly useful on systems which provide for example a direct-mapped memory segment. This function works by stealing pages from the (to be) managed memory pool, which has already been provided to <a class="link-man" href="../9/uvm">uvm(9)</a> in the vm_physmem[] array. The pages are then mapped, or otherwise made accessible to the kernel, in a machine-dependent way. The memory must be zeroed by <b class="fname">pmap_steal_memory</b>(). Note that memory allocated with <b class="fname">pmap_steal_memory</b>() will never be freed, and mappings made by <b class="fname">pmap_steal_memory</b>() must never be &#8220;forgotten&#8221;.<p>
Note that <b class="fname">pmap_steal_memory</b>() should not be used as a general-purpose early-startup memory allocation routine. It is intended to be used only by the <b class="fname">uvm_pageboot_alloc</b>() routine and its supporting routines. If you need to allocate memory before the virtual memory system is initialized, use <b class="fname">uvm_pageboot_alloc</b>(). See <a class="link-man" href="../9/uvm">uvm(9)</a> for more information.<p>
The <b class="fname">pmap_steal_memory</b>() function returns the kernel-accessible address of the allocated memory. If no memory can be allocated, or if allocated memory cannot be mapped, the function must panic.<p>
If the <b class="fname">pmap_steal_memory</b>() function uses address space from the range provided to <a class="link-man" href="../9/uvm">uvm(9)</a> by the <b class="fname">pmap_virtual_space</b>() call, then <b class="fname">pmap_steal_memory</b>() must adjust <i class="farg">*vstartp</i> and <i class="farg">*vendp</i> upon return.<p>
The <b class="fname">pmap_steal_memory</b>() function is enabled by defining the C pre-processor macro <span class="define">PMAP_STEAL_MEMORY</span> in <b class="includes">&lt;<a class="link-includes">machine/pmap.h</a>&gt;</b>.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
vaddr_t <b class="fname">pmap_growkernel</b>(<i class="farg">vaddr_t maxkvaddr</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Management of the kernel virtual address space is complicated by the fact that it is not always safe to wait for resources with which to map a kernel virtual address. However, it is not always desirable to pre-allocate all resources necessary to map the entire kernel virtual address space.<p>
The <b class="fname">pmap_growkernel</b>() interface is designed to help alleviate this problem. The virtual memory startup code may choose to allocate an initial set of mapping resources (e.g., page tables) and set an internal variable indicating how much kernel virtual address space can be mapped using those initial resources. Then, when the virtual memory system wishes to map something at an address beyond that initial limit, it calls <b class="fname">pmap_growkernel</b>() to pre-allocate more sources with which to create the mapping. Note that once additional kernel virtual address space mapping resources have been allocated, they should not be freed; it is likely they will be needed again.<p>
The <b class="fname">pmap_growkernel</b>() function returns the new maximum kernel virtual address that can be mapped with the resources it has available. If new resources cannot be allocated, <b class="fname">pmap_growkernel</b>() must panic.<p>
The <b class="fname">pmap_growkernel</b>() function is enabled by defining the C pre-processor macro <span class="define">PMAP_GROWKERNEL</span> in <b class="includes">&lt;<a class="link-includes">machine/pmap.h</a>&gt;</b>.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_fork</b>(<i class="farg">pmap_t src_map</i>, <i class="farg">pmap_t dst_map</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Some <b class="name">pmap</b> implementations may need to keep track of other information not directly related to the virtual address space. For example, on the i386 port, the Local Descriptor Table state of a process is associated with the pmap (this is due to the fact that applications manipulate the Local Descriptor Table directly expect it to be logically associated with the virtual memory state of the process).<p>
The <b class="fname">pmap_fork</b>() function is provided as a way to associate information from <i class="farg">src_map</i> with <i class="farg">dst_map</i> when a <span class="define">vmspace</span> is forked. <b class="fname">pmap_fork</b>() is called from <b class="fname">uvmspace_fork</b>().<p>
The <b class="fname">pmap_fork</b>() function is enabled by defining the C pre-processor macro <span class="define">PMAP_FORK</span> in <b class="includes">&lt;<a class="link-includes">machine/pmap.h</a>&gt;</b>.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
vaddr_t <b class="fname">PMAP_MAP_POOLPAGE</b>(<i class="farg">paddr_t pa</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
This function is used by the <a class="link-man" href="../9/pool">pool(9)</a> memory pool manager. Pools allocate backing pages one at a time. This is provided as a means to use hardware features such as a direct-mapped memory segment to map the pages used by the <a class="link-man" href="../9/pool">pool(9)</a> allocator. This can lead to better performance by e.g. reducing TLB contention.<p>
<b class="fname">PMAP_MAP_POOLPAGE</b>() returns the kernel-accessible address of the page being mapped. It must always succeed.<p>
The use of <b class="fname">PMAP_MAP_POOLPAGE</b>() is enabled by defining it as a C pre-processor macro in <b class="includes">&lt;<a class="link-includes">machine/pmap.h</a>&gt;</b>. If <b class="fname">PMAP_MAP_POOLPAGE</b>() is defined, <b class="fname">PMAP_UNMAP_POOLPAGE</b>() must also be defined.<p>
The following is an example of how to define <b class="fname">PMAP_MAP_POOLPAGE</b>():<p>
<pre style="margin-left: 5.00ex;" class="lit display">
#define PMAP_MAP_POOLPAGE(pa)   MIPS_PHYS_TO_KSEG0((pa))</pre>
<p>
This takes the physical address of a page and returns the KSEG0 address of that page on a MIPS processor.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
paddr_t <b class="fname">PMAP_UNMAP_POOLPAGE</b>(<i class="farg">vaddr_t va</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
This function is the inverse of <b class="fname">PMAP_MAP_POOLPAGE</b>().<p>
<b class="fname">PMAP_UNMAP_POOLPAGE</b>() returns the physical address of the page corresponding to the provided kernel-accessible address.<p>
The use of <b class="fname">PMAP_UNMAP_POOLPAGE</b>() is enabled by defining it as a C pre-processor macro in <b class="includes">&lt;<a class="link-includes">machine/pmap.h</a>&gt;</b>. If <b class="fname">PMAP_UNMAP_POOLPAGE</b>() is defined, <b class="fname">PMAP_MAP_POOLPAGE</b>() must also be defined.<p>
The following is an example of how to define <b class="fname">PMAP_UNMAP_POOLPAGE</b>():<p>
<pre style="margin-left: 5.00ex;" class="lit display">
#define PMAP_UNMAP_POOLPAGE(pa) MIPS_KSEG0_TO_PHYS((va))</pre>
<p>
This takes the KSEG0 address of a previously-mapped pool page and returns the physical address of that page on a MIPS processor.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">PMAP_PREFER</b>(<i class="farg">vaddr_t hint</i>, <i class="farg">vaddr_t *vap</i>, <i class="farg">vsize_t sz</i>, <i class="farg">int td</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
This function is used by <a class="link-man" href="../9/uvm_map">uvm_map(9)</a> to adjust a virtual address being allocated in order to avoid cache alias problems. If necessary, the virtual address pointed by <i class="farg">vap</i> will be advanced. <i class="farg">hint</i> is an object offset which will be mapped into the resulting virtual address, and <i class="farg">sz</i> is size of the region being mapped in bytes. <i class="farg">td</i> indicates if the machine dependent pmap uses the topdown VM.<p>
The use of <b class="fname">PMAP_PREFER</b>() is enabled by defining it as a C pre-processor macro in <b class="includes">&lt;<a class="link-includes">machine/pmap.h</a>&gt;</b>.</dd>
<dt class="list-tag" style="margin-top: 1.00em;">
void <b class="fname">pmap_procwr</b>(<i class="farg">struct proc *p</i>, <i class="farg">vaddr_t va</i>, <i class="farg">vsize_t size</i>)</dt>
<dd class="list-tag" style="margin-left: 6.00ex;">
Synchronize CPU instruction caches of the specified range. The address space is designated by <i class="farg">p</i>. This function is typically used to flush instruction caches after code modification.<p>
The use of <b class="fname">pmap_procwr</b>() is enabled by defining a C pre-processor macro <span class="define">PMAP_NEED_PROCWR</span> in <b class="includes">&lt;<a class="link-includes">machine/pmap.h</a>&gt;</b>.</dd>
</dl>
</div>
</div>
<div class="section">
<h1 id="x53454520414c534f">SEE ALSO</h1> <a class="link-man" href="../9/uvm">uvm(9)</a></div>
<div class="section">
<h1 id="x484953544f5259">HISTORY</h1> The <b class="name">pmap</b> module was originally part of the design of the virtual memory system in the Mach Operating System. The goal was to provide a clean separation between the machine-independent and the machine-dependent portions of the virtual memory system, in stark contrast to the original <span class="unix">3BSD</span> virtual memory system, which was specific to the VAX.<p>
Between <span class="unix">4.3BSD</span> and <span class="unix">4.4BSD</span>, the Mach virtual memory system, including the <b class="name">pmap</b> API, was ported to <span class="unix">BSD</span> and included in the <span class="unix">4.4BSD</span> release.<p>
<span class="unix">NetBSD</span> inherited the <span class="unix">BSD</span> version of the Mach virtual memory system. <span class="unix">NetBSD&#160;1.4</span> was the first <span class="unix">NetBSD</span> release with the new <a class="link-man" href="../9/uvm">uvm(9)</a> virtual memory system, which included several changes to the <b class="name">pmap</b> API. Since the introduction of <a class="link-man" href="../9/uvm">uvm(9)</a>, the <b class="name">pmap</b> API has evolved further.</div>
<div class="section">
<h1 id="x415554484f5253">AUTHORS</h1> The original Mach VAX <b class="name">pmap</b> module was written by <span class="author">Avadis Tevanian, Jr.</span> and <span class="author">Michael Wayne Young</span>.<p>
<span class="author">Mike Hibler</span> did the integration of the Mach virtual memory system into <span class="unix">4.4BSD</span> and implemented a <b class="name">pmap</b> module for the Motorola 68020+68851/68030/68040.<p>
The <b class="name">pmap</b> API as it exists in <span class="unix">NetBSD</span> is derived from <span class="unix">4.4BSD</span>, and has been modified by <span class="author">Chuck Cranor</span>, <span class="author">Charles M. Hannum</span>, <span class="author">Chuck Silvers</span>, <span class="author">Wolfgang Solfrank</span>, <span class="author">Bill Sommerfeld</span>, and <span class="author">Jason R. Thorpe</span>.<p>
The author of this document is <span class="author">Jason R. Thorpe</span> &#60;thorpej@NetBSD.org&#62;.</div>
<div class="section">
<h1 id="x42554753">BUGS</h1> The use and definition of <b class="fname">pmap_activate</b>() and <b class="fname">pmap_deactivate</b>() needs to be reexamined.<p>
The use of <b class="fname">pmap_copy</b>() needs to be reexamined. Empirical evidence suggests that performance of the system suffers when <b class="fname">pmap_copy</b>() actually performs its defined function. This is largely due to the fact that the copy of the virtual-to-physical mappings is wasted if the process calls <a class="link-man" href="../2/execve">execve(2)</a> after <a class="link-man" href="../2/fork">fork(2)</a>. For this reason, it is recommended that <b class="name">pmap</b> implementations leave the body of the <b class="fname">pmap_copy</b>() function empty for now.</div>
<table summary="Document Footer" class="foot" width="100%">
<col width="50%">
<col width="50%">
<tbody>
<tr>
<td class="foot-date">
February 16, 2012</td>
<td class="foot-os" align="right">
NetBSD 7.99</td>
</tr>
</tbody>
</table>
</div>
</body>
</html>

